= Node Classification
:level: Intermediate
:page-level: Intermediate
:author: Clair Sullivan
:category: graph-data-science
:tags: graph-data-science, graph-algorithms, machine-learning
:description: This guide covers machine learning-based node classification using the Neo4j Data Science Library.
:page-aliases: ROOT:graph-algorithms.adoc

.Goals
[abstract]
In this guide, we will learn about graph embeddings.

.Prerequisites
[abstract]
Please have link:/download[Neo4j^] (version 4.2.3 or later) and link:/download-center/#algorithms[Graph Data Science Library^] (version 1.5 or later) downloaded and installed to use graph embeddings.  You should also have https://github.com/neo4j-contrib/neo4j-apoc-procedures[APOC^] (version 4.1.0.6 or later).

[role=expertise {level}]
{level}

[#node-prediction]
== What is node prediction?

Node prediction is a machine learning concept whereby existing node and edge properties can be used to train a model that will learn node classifications.  This model can then be applied to one or a set of nodes to predict their node classifications.

Node classification is based on logistic regression, which is dicussed here:

*** insert link to some generalized node classification guide

Penalty :: L1 norm used to prevent overfitting of the training data

[NOTE]
====
The code examples used in this guide can be found in https://github.com/AliciaFrame/ML_with_GDS[this GitHub repository^]. 
==== 

[#marvel-dataset]
== Marvel Universe dataset

In this example we will be using a dataset from the comics and movies associated with the Marvel Universe.  This dataset can be found https://gist.github.com/tomasonjo/fbc6d617c3f6476a3a825b5dd22fd29a[here^].  It contains 40,616 characters and 65,870 relationships connecting them.  Additionally, the characters have numerous properties that can be assosicated with each node.  We will be using this dataset to try and predict, off of a series of characters for training purposes, which characters are X-Men and which are not.

=== Data preparation

We will begin by loading in the data to the database from a series of CSV files available online.  This can be done with the following query:

[source, cypher]
----
CALL apoc.schema.assert({Character:['name']},{Comic:['id'], Character:['id'], Event:['id'], Group:['id']});

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/heroes.csv" as row
CREATE (c:Character)
SET c += row;

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/groups.csv" as row
CREATE (c:Group)
SET c += row;

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/events.csv" as row
CREATE (c:Event)
SET c += row;

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/comics.csv" as row
CREATE (c:Comic)
SET c += apoc.map.clean(row,[],["null"]);

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/heroToComics.csv" as row
MATCH (c:Character{id:row.hero})
MATCH (co:Comic{id:row.comic})
MERGE (c)-[:APPEARED_IN]->(co);

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/heroToEvent.csv" as row
MATCH (c:Character{id:row.hero})
MATCH (e:Event{id:row.event})
MERGE (c)-[:PART_OF_EVENT]->(e);

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/heroToGroup.csv" as row
MATCH (c:Character{id:row.hero})
MATCH (g:Group{id:row.group})
MERGE (c)-[:PART_OF_GROUP]->(g);

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/heroToHero.csv" as row
MATCH (s:Character{id:row.source})
MATCH (t:Character{id:row.target})
CALL apoc.create.relationship(s,row.type, {}, t) YIELD rel
RETURN distinct 'done';

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/heroStats.csv" as row
MATCH (s:Character{id:row.hero})
CREATE (s)-[:HAS_STATS]->(stats:Stats)
SET stats += apoc.map.clean(row,['hero'],[]);

LOAD CSV WITH HEADERS FROM "https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/Marvel/heroFlight.csv" as row
MATCH (s:Character{id:row.hero})
SET s.flight = row.flight;

MATCH (s:Stats)
WITH keys(s) as keys LIMIT 1
MATCH (s:Stats)
UNWIND keys as key
CALL apoc.create.setProperty(s, key, toInteger(s[key]))
YIELD node
RETURN distinct 'done';
----

This query creates a series of nodes and their labels and properties: `Comic`, `Character`, `Stats` along with a variety of edges such as which comics the characters appeared in which comics, who is an enemby of whom, etc.  You can see a schema of this graph using `CALL db.schema.visualization()` here:

image::marvel-schema.png[Delete all Nodes, link="{imagesdir}/marvel-schema.png",role="popup-link"]

(Note that for the simplicity of the image we are not showing the node properties since there are many.)

We next bring in the character traits from the stats to be node properties:

[source, cypher]
----
MATCH (c:Character)-[:HAS_STATS]->(s)
WITH c, s.strength as strength, s.fighting_skills as fighting_skills, s.durability as durability, s.speed as speed, s.intelligence as intelligence, s.energy as energy
SET c.strength=strength,
    c.fighting_skills=fighting_skills,
    c.durability=durability,
    c.speed=speed,
    c.intelligence=intelligence,
    c.energy=energy
RETURN count(c)
----

These node properties will eventually be used to build the node classification model via both embeddings as well as the tabular approach.

Next, we set up the co-occurance of characters such that we can identify which characters appear with which other characters and how often (which will be used to identify the edge weighting).  This is done via:

[source, cypher]
----
MATCH (c1:Character)-[:APPEARED_IN]->(c:Comic)<-[:APPEARED_IN]-(c2:Character) 
WITH c1, c2, count(c) as weight
MERGE (c1)-[:APPEARED_WITH{times:weight}]->(c2)
MERGE (c2)-[:APPEARED_WITH{times:weight}]->(c1)
----

=== Feature engineering

Once our data is loaded in, it is time to start the process of engineering the features that will be used to populate our mode.  For example, we might consider a variety of https://neo4j.com/docs/graph-data-science/current/algorithms/centrality/[centrality measures] of the character to be a feature that would be useful to train with.  To obtain this, we first create an in-memory graph as:

[source, cypher]
----
CALL gds.graph.create(
  'marvel-character-graph',
  {
    Person: {
      label: 'Character',
      properties: { 
      strength:{property:'strength',defaultValue:0},
      fighting_skills:{property:'fighting_skills', defaultValue:0},
      durability:{property:'durability', defaultValue:0},
      speed:{property:'speed', defaultValue:0},
      intelligence:{property:'intelligence', defaultValue:0},
      group_membership:{property:'group_membership',defaultValue:[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}
      }
    }
  }, {
    APPEARS_WITH_UNDIRECTED: {
      type: 'APPEARED_WITH',
      orientation: 'UNDIRECTED',
      aggregation: 'SINGLE',
      properties: ['times']
    },
    APPEARS_WITH_DIRECTED: {
      type: 'APPEARED_WITH',
      orientation: 'NATURAL',
      properties: ['times'],
      aggregation: 'SINGLE'
    },
    ALLY_UNDIRECTED: {
      type: 'ALLY',
      orientation: 'UNDIRECTED',
      aggregation: 'SINGLE'
    },
    ALLY_DIRECTED: {
      type: 'ALLY',
      orientation: 'NATURAL',
      aggregation: 'SINGLE'
    },    
    ENEMY_UNDIRECTED: {
      type: 'ENEMY',
      orientation: 'UNDIRECTED',
      aggregation: 'SINGLE'
    },
    ENEMY_DIRECTED: {
      type: 'ENEMY',
      orientation: 'NATURAL',
      aggregation: 'SINGLE'
    }
   
});
----

and then we use this graph to calculate the https://neo4j.com/docs/graph-data-science/current/algorithms/page-rank/[PageRank], https://neo4j.com/docs/graph-data-science/current/algorithms/betweenness-centrality/[Betweenness Centrality], and https://neo4j.com/docs/graph-data-science/current/algorithms/hits/[Hyperlink-Induced Topic Search] (HITS) of each node and write those values back to the database:

[source, cypher]
----
// pageRank
CALL gds.pageRank.write('marvel-character-graph',{
     relationshipTypes: ['APPEARS_WITH_DIRECTED'],
     writeProperty: 'appeared_with_pageRank'
});
CALL gds.pageRank.write('marvel-character-graph',{
     relationshipTypes: ['ALLY_DIRECTED'],
     writeProperty: 'ally_pageRank'
});
CALL gds.pageRank.write('marvel-character-graph',{
     relationshipTypes: ['ENEMY_DIRECTED'],
     writeProperty: 'enemy_pageRank'
});

// betweenness
CALL gds.betweenness.write('marvel-character-graph',{
     relationshipTypes: ['APPEARS_WITH_UNDIRECTED'],
     writeProperty: 'appeared_with_betweenness'
});
CALL gds.betweenness.write('marvel-character-graph',{
     relationshipTypes: ['ALLY_UNDIRECTED'],
     writeProperty: 'ally_betweenness'
});
CALL gds.betweenness.write('marvel-character-graph',{
     relationshipTypes: ['ENEMY_UNDIRECTED'],
     writeProperty: 'enemy_betweenness'
});

//HITS
CALL gds.alpha.hits.write('marvel-character-graph',{
     relationshipTypes: ['APPEARS_WITH_DIRECTED'],
     hitsIterations: 50,
     authProperty: 'appeared_with_auth',
     hubProperty: 'appeared_with_hub'
});
CALL gds.alpha.hits.write('marvel-character-graph',{
     relationshipTypes: ['ALLY_DIRECTED'],
     hitsIterations: 50,
     authProperty: 'appeared_with_auth',
     hubProperty: 'appeared_with_hub'
});
CALL gds.alpha.hits.write('marvel-character-graph',{
     relationshipTypes: ['ENEMY_DIRECTED'],
     hitsIterations: 50,
     authProperty: 'appeared_with_auth',
     hubProperty: 'appeared_with_hub'
});
----

We will also want these values added to the in-memory graph for the sake of calculating graph embeddings in the next step, which is achieved through the `.mutate()` command:

[source, cypher]
----
// pageRank
CALL gds.pageRank.mutate('marvel-character-graph',{
     relationshipTypes: ['APPEARS_WITH_DIRECTED'],
     mutateProperty: 'appeared_with_pageRank'
});
CALL gds.pageRank.mutate('marvel-character-graph',{
     relationshipTypes: ['ALLY_DIRECTED'],
     mutateProperty: 'ally_pageRank'
});
CALL gds.pageRank.mutate('marvel-character-graph',{
     relationshipTypes: ['ENEMY_DIRECTED'],
     mutateProperty: 'enemy_pageRank'
});

// betweenness
CALL gds.betweenness.mutate('marvel-character-graph',{
     relationshipTypes: ['APPEARS_WITH_UNDIRECTED'],
     mutateProperty: 'appeared_with_betweenness'
});
CALL gds.betweenness.mutate('marvel-character-graph',{
     relationshipTypes: ['ALLY_UNDIRECTED'],
     mutateProperty: 'ally_betweenness'
});
CALL gds.betweenness.mutate('marvel-character-graph',{
     relationshipTypes: ['ENEMY_UNDIRECTED'],
     mutateProperty: 'enemy_betweenness'
});

//HITS
CALL gds.alpha.hits.mutate('marvel-character-graph',{
     relationshipTypes: ['APPEARS_WITH_DIRECTED'],
     hitsIterations: 50,
     authProperty: 'appeared_with_auth',
     hubProperty: 'appeared_with_hub'
});
CALL gds.alpha.hits.mutate('marvel-character-graph',{
     relationshipTypes: ['ALLY_DIRECTED'],
     hitsIterations: 50,
     authProperty: 'appeared_with_auth',
     hubProperty: 'appeared_with_hub'
});
CALL gds.alpha.hits.mutate('marvel-character-graph',{
     relationshipTypes: ['ENEMY_DIRECTED'],
     hitsIterations: 50,
     authProperty: 'appeared_with_auth',
     hubProperty: 'appeared_with_hub'
});
----

Lastly, we will use the https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/[Fast Random Projection] (FastRP) embedding algorithm to create embedding vectors for each node, that will be used in one of our node classifications.  

[NOTE]
====
For more information on graph embeddings and how they can be used, see link:/developer/graph-data-science/graph-embeddings[Applied Graph Embeddings].

In this next section we will demonstrating how to run the node classifcation algorithm on two different models: one where we use the properties associated with each character and conver them to tabular format for training and one where we use the FastRP graph embedding algorithm to create vector embeddings for the training and test set in order to predict node classes.  ***insert link to FastRP***

***insert some relevant definitions***




[#use-cases-graph-embeddings]
== Use cases for graph embeddings



There are several use cases that are well suited for graph embeddings:

* We can visually explore the data by reducing the embeddings to 2 or 3 dimensions with the help of algorithms like https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding[t-distributed stochastic neighbor embedding^] (t-SNE) and https://en.wikipedia.org/wiki/Principal_component_analysis[Principle Component Analysis^] (PCA).

* We could build a kNN similarity graph from the embeddings.
The similarity graph could then be used to make recommendations as part of a k-Nearest Neighbors query.

* We can use the embeddings as the features to feed into a machine learning model, rather than generating those features by hand.
In this use case, embeddings can be considered an implementation of https://en.wikipedia.org/wiki/Feature_learning[Representational Learning^].

[#supported-graph-embeddings]
== Neo4j's graph embeddings

The Neo4j link:/graph-data-science-library[Graph Data Science Library^] supports several graph embedding algorithms.

[opts=header]
|===
| Name | Speed | Supports node properties? | Implementation details
| link:#random-projection[Random Projection] | Fast |   No | Linear Algebra
| link:#node2Vec[node2Vec] |  Intermediate |  No | Neural Network
| link:#graph-sage[GraphSAGE] | Slow |   Yes | Neural Network
|===

All the embedding algorithms work on a monopartite undirected input graph.

[#random-projection]
Random Projection ::
The Random Projection embedding uses sparse random projections to generate embeddings.
It is an implementation of the https://arxiv.org/pdf/1908.11512.pdf[FastRP algorithm^].
It is the fastest of the embedding algorithms and can therefore be useful for obtaining baseline embeddings.
The embeddings it generates are often equally performant as more complex algorithms that take longer to run.

link:/docs/graph-data-science/1.3-preview/algorithms/alpha/fastrp/fastrp/[Read Random Projection reference documentation^, role="medium button"]

[#node2Vec]
node2Vec ::
https://arxiv.org/pdf/1607.00653.pdf[node2Vec^] computes embeddings based on biased random walks of a node's neighborhood.
The algorithm trains a single-layer feedforward neural network, which is used to predict the likelihood that a node will occur in a walk based on the occurrence of another node.
node2Vec has parameters that can be tuned to control whether the random walks behave more like breadth first or depth first searches.
This tuning allows the embedding to either capture homophily (similar embeddings capture network communities) or structural equivalence (similar embeddings capture similar structural roles of nodes).

link:/docs/graph-data-science/1.3-preview/algorithms/node-embeddings/node2vec/[Read node2Vec reference documentation^, role="medium button"]

[#graph-sage]
GraphSAGE ::
This https://arxiv.org/pdf/1706.02216.pdf[algorithm^] is the only one that supports node properties.
Training embeddings that include node properties can be useful for including information beyond the topology of the graph, like meta data, attributes, or the results of other graph algorithms.
GraphSAGE differs from the other algorithms in that it learns a function to calculate an embedding rather than training individual embeddings for each node.

link:/docs/graph-data-science/1.3-preview/algorithms/alpha/graph-sage/[Read GraphSAGE reference documentation^, role="medium button"]
